{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pytorch_lightning as pl\nimport pandas as pd\nimport os \nimport torch\nimport torchvision\nfrom torch.utils.data import Dataset ,DataLoader\nfrom torchmetrics import Accuracy\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nimport numpy as np\nimport torch\nfrom sklearn.model_selection import train_test_split \nfrom torchvision import datasets, transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models\n# from lightning.pytorch.loggers import WandbLogger\nfrom pytorch_lightning.loggers import WandbLogger\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:49:43.322840Z","iopub.execute_input":"2023-04-10T19:49:43.323394Z","iopub.status.idle":"2023-04-10T19:49:51.365436Z","shell.execute_reply.started":"2023-04-10T19:49:43.323354Z","shell.execute_reply":"2023-04-10T19:49:51.364333Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n\n\n\n# use directly wandb module\n# wandb.config[\"key\"] = \"a2e6402ce9fe2ebe1f01d5332c4fafa210b0dc0c\"\n# wandb.config.update()\n\n\n\nwandb.login(key=\"a2e6402ce9fe2ebe1f01d5332c4fafa210b0dc0c\")\npName = \"Assignment 2 Part A main 4\"\nrun_obj=wandb.init( project=pName)\n#     obj = CNNModel(config.activation_function,config.batch_normalization,config.data_augmentation,config.filter_organisation, config.drop_out)\n\n# Set up the configuration for your sweep using the `wandb.sweep` function\nsweep_config = {\n    'method': 'bayes', # or 'grid'\n    'metric': {'name': 'val_loss', 'goal': 'minimize'},\n    'parameters': {\n        'drop_out': {\"values\": [0.2, 0.3]},\n        \"activation_function\": {\n              \"values\": [ \"ReLU\", \"SiLU\", \"GELU\", \"Mish\"]\n          },\n          \n          \"learning_rate\": {\n              \"values\": [1e-3, 1e-4]\n          }\n          ,\n        \"filter_organisation\":{\n            \"values\":[[8,8,8,8,8],[16,16,16,16,16],[32,32,32,32,32],[64,64,64,64,64]]\n        },\n        \"data_augmentation\":{\n            \"values\":[\"Yes\",\"No\"]\n        },\n        \"batch_normalization\":{\n            \"values\":[\"Yes\",\"No\"]\n        },\n          \"epochs\": {\n              \"values\": [5, 10]\n          },\n    }\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:49:51.367758Z","iopub.execute_input":"2023-04-10T19:49:51.368164Z","iopub.status.idle":"2023-04-10T19:50:25.334163Z","shell.execute_reply.started":"2023-04-10T19:49:51.368124Z","shell.execute_reply":"2023-04-10T19:50:25.332862Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m008\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230410_194954-3fvq45v8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/3fvq45v8' target=\"_blank\">stellar-sea-1</a></strong> to <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/3fvq45v8' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/3fvq45v8</a>"},"metadata":{}}]},{"cell_type":"markdown","source":"CNN model ","metadata":{}},{"cell_type":"code","source":"class CNNModel(pl.LightningModule):\n    \n    def __init__(self,activation_function,batch_normalization,data_augmentation,filter_organisation,drop_out):\n        self.activation_function=activation_function\n        self.batch_normalization=batch_normalization\n#         self.data_augmentation=data_augmentation\n        super(CNNModel, self).__init__()\n        \n        self.cnv1 = torch.nn.Conv2d(3, filter_organisation[0], 3)\n        self.cnv2 = torch.nn.Conv2d(filter_organisation[0], filter_organisation[1], 3)\n        self.cnv3 = torch.nn.Conv2d(filter_organisation[1], filter_organisation[2], 3)      \n        self.cnv4 = torch.nn.Conv2d(filter_organisation[2], filter_organisation[3], 3)\n        self.cnv5 = torch.nn.Conv2d(filter_organisation[3], filter_organisation[4], 3)\n        \n        if(activation_function==\"ReLU\"):\n            self.activation_function=nn.ReLU()\n        elif(activation_function==\"GELU\"):\n            self.activation_function=nn.GELU()\n        elif(activation_function==\"SiLU\"):\n            self.activation_function=nn.SiLU()\n        elif(activation_function==\"Mish\"):\n            self.activation_function=nn.Mish()\n        \n        stride=2\n        input_size=256\n        \n        DenseLayerSize=input_size\n        for filter in filter_organisation:\n            DenseLayerSize = (DenseLayerSize-4)//stride + 1\n        \n        self.bn = nn.BatchNorm1d(DenseLayerSize*DenseLayerSize*filter_organisation[4])\n        self.mxpool = nn.MaxPool2d(2)\n        self.flat = nn.Flatten()\n        self.fc= nn.Linear(DenseLayerSize*DenseLayerSize*filter_organisation[4],10)\n        self.softmax = nn.Softmax()\n        self.learning_rate=0.001\n        self.dropout = nn.Dropout(p=drop_out)\n        self.save_hyperparameters()\n#         self.batch_normalization=batch_normalization\n\n    def forward(self,x):\n#         print(x.shape)\n        out=self.activation_function(self.cnv1(x))\n        out=self.mxpool(out)\n#         print(\"print: mp1    \",out.shape)\n\n        out=self.activation_function(self.cnv2(out))\n        out=self.mxpool(out)\n#         print(\"print: mp2    \",out.shape)\n\n        out=self.activation_function(self.cnv3(out))\n        out=self.mxpool(out)\n#         print(\"print: mp3    \",out.shape)\n\n        out=self.activation_function(self.cnv4(out))\n        out=self.mxpool(out)\n#         print(\"print: mp4    \",out.shape)\n\n        out=self.activation_function(self.cnv5(out))\n        \n        out = self.mxpool(out)\n#         print(\"print: mp5    \",out.shape)\n        out=self.flat(out)\n#         print(\"print: result    \",out.shape)\n        if(self.batch_normalization==\"Yes\"):\n            out=self.bn(out) \n        out = self.dropout(out)\n\n        out = self.activation_function(self.fc(out))\n        return out\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n        accuracy = (logits.argmax(dim=1) == y).float().mean()\n        self.log(\"train_accuracy\", accuracy, prog_bar=True,on_epoch=True)\n#         wandb.log({\"train/loss\": loss})\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n\n        self.log(\"val_loss\", loss,prog_bar=True, on_epoch=True)\n#         print(\"val Loss:\",loss)\n        accuracy = (logits.argmax(dim=1) == y).float().mean()\n#         print(\"val_accuracy: \",accuracy)\n        self.log(\"val_accuracy\", accuracy, prog_bar=True,on_epoch=True)\n\n    \n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        accuracy = (logits.argmax(dim=1) == y).float().mean()\n#         print(\"test_accuracy: \",accuracy)\n        self.log(\"test_loss\", loss, prog_bar=True, on_epoch=True)\n        self.log(\"test_accuracy\", accuracy, prog_bar=True,on_epoch=True)\n        \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:50:25.339281Z","iopub.execute_input":"2023-04-10T19:50:25.339652Z","iopub.status.idle":"2023-04-10T19:50:25.369916Z","shell.execute_reply.started":"2023-04-10T19:50:25.339612Z","shell.execute_reply":"2023-04-10T19:50:25.368882Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n\n# # # # testing\n# # Define data transformations\n# transform = transforms.Compose([\n#     transforms.Resize((256,256)),\n\n#     transforms.ToTensor(),\n\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#                         std=[0.229, 0.224, 0.225])\n# ])\n\n# transform_augmented = transforms.Compose([\n#     transforms.Resize((256,256)),\n#     transforms.AutoAugment(),\n\n#     transforms.ToTensor(),\n\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#                         std=[0.229, 0.224, 0.225])\n# ])\n\n\n\n# dataset = datasets.ImageFolder('/kaggle/input/inaturalist12k/Data/inaturalist_12K/train', transform=transform_augmented)\n\n# test_dataset = datasets.ImageFolder('/kaggle/input/inaturalist12k/Data/inaturalist_12K/val', transform=transform)\n\n\n\n# # Split dataset into training and testing sets\n# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(0.8*len(dataset)), len(dataset)-int(0.8*len(dataset))])\n\n# # Create data loader objects for training and testing sets\n# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n# val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n\n\n\n# obj = CNNModel(\"ReLU\",\"Yes\",\"Yes\",[64,64,64,64,32], 0.3)\n# trainer = pl.Trainer(max_epochs=3, accelerator=\"gpu\", devices=1)\n# trainer.fit(model=obj,train_dataloaders=train_dataloader,val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:50:25.372476Z","iopub.execute_input":"2023-04-10T19:50:25.373530Z","iopub.status.idle":"2023-04-10T19:50:25.382954Z","shell.execute_reply.started":"2023-04-10T19:50:25.373490Z","shell.execute_reply":"2023-04-10T19:50:25.381860Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sweep():\n    wandb.init()\n# sweep_id = wandb.sweep(sweep_config,project=\"Asg 1 Final\")\n# wandb.agent(sweep_id, sweep)\n    wandb_logger = WandbLogger()\n    config = wandb.config\n\n    # Define data transformations\n    transform = transforms.Compose([\n        transforms.Resize((256,256)),\n\n        transforms.ToTensor(),\n\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225])\n    ])\n\n    transform_augmented = transforms.Compose([\n        transforms.Resize((256,256)),\n        transforms.AutoAugment(),\n\n        transforms.ToTensor(),\n\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225])\n    ])\n\n\n    # Load dataset from directory\n    if(config.data_augmentation==\"No\"):\n        dataset = datasets.ImageFolder('/kaggle/input/inaturalist12k/Data/inaturalist_12K/train', transform=transform)\n    else:\n        dataset = datasets.ImageFolder('/kaggle/input/inaturalist12k/Data/inaturalist_12K/train', transform=transform_augmented)\n\n    test_dataset = datasets.ImageFolder('/kaggle/input/inaturalist12k/Data/inaturalist_12K/val', transform=transform)\n\n\n\n    # Split dataset into training and testing sets\n    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(0.8*len(dataset)), len(dataset)-int(0.8*len(dataset))])\n\n    # Create data loader objects for training and testing sets\n    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n\n\n    print(config.activation_function,config.batch_normalization,config.data_augmentation,config.filter_organisation, config.drop_out)\n    \n    obj = CNNModel(config.activation_function,config.batch_normalization,config.data_augmentation,config.filter_organisation, config.drop_out)\n    \n    trainer = pl.Trainer(max_epochs=config.epochs, accelerator=\"gpu\", devices=1, logger=wandb_logger)\n    \n    trainer.fit(model=obj,train_dataloaders=train_dataloader,val_dataloaders=val_dataloader)\n    # trainer.test(model=net, datamodule=dataset, ckpt_path='best')\n\n    run_name = \"lr_{}_ac_{}_bn_{}_da_{}_bs_{}_dp_{}\".format(config.learning_rate, config.activation_function,config.batch_normalization,config.data_augmentation,config.filter_organisation, config.drop_out)\n    print(run_name)\n    wandb.run.name = run_name\n    wandb.run.save()\n#     wandb.finish()\n\n# Initialize the WandB sweep\nsweep_id = wandb.sweep(sweep_config,project=pName)\nwandb.agent(sweep_id, sweep)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T19:50:25.387821Z","iopub.execute_input":"2023-04-10T19:50:25.388511Z","iopub.status.idle":"2023-04-10T19:55:21.264204Z","shell.execute_reply.started":"2023-04-10T19:50:25.388474Z","shell.execute_reply":"2023-04-10T19:55:21.263221Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: aysozaak\nSweep URL: https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak\n","output_type":"stream"},{"name":"stderr","text":"wandb: Waiting for W&B process to finish... (success).\nwandb: 🚀 View run stellar-sea-1 at: https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/3fvq45v8\nwandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20230410_194954-3fvq45v8/logs\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a31ybp0u with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: SiLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organisation: [16, 16, 16, 16, 16]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230410_195044-a31ybp0u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/a31ybp0u' target=\"_blank\">iconic-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/a31ybp0u' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/a31ybp0u</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n  \"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\n","output_type":"stream"},{"name":"stdout","text":"SiLU Yes Yes [16, 16, 16, 16, 16] 0.2\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'activation_function' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_normalization' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_augmentation' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'filter_organisation' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_out' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c785b8828b0b45b7aa7bcbc019e8b94a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f07e3d73ee04cefba5a3b26ce5fb59d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">iconic-sweep-1</strong> at: <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/a31ybp0u' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/a31ybp0u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230410_195044-a31ybp0u/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run a31ybp0u errored: TypeError(\"'str' object is not callable\")\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0fo9tt78 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: Mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: No\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organisation: [8, 8, 8, 8, 8]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.14.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230410_195138-0fo9tt78</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/0fo9tt78' target=\"_blank\">rose-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/sweeps/aysozaak</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/0fo9tt78' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/0fo9tt78</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'activation_function' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_normalization' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_augmentation' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'filter_organisation' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_out' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"name":"stdout","text":"Mish Yes No [8, 8, 8, 8, 8] 0.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b879341e1d294e49ae09411561452a41"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"name":"stdout","text":"Error in callback <function _WandbInit._pause_backend at 0x7a9986018710> (for post_run_cell):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.041 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.026331…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42d2d731daa944689b95a336538a81be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁</td></tr><tr><td>train_accuracy_step</td><td>▁█</td></tr><tr><td>train_loss_step</td><td>█▁</td></tr><tr><td>trainer/global_step</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>train_accuracy_step</td><td>0.28125</td></tr><tr><td>train_loss_step</td><td>2.05953</td></tr><tr><td>trainer/global_step</td><td>99</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rose-sweep-2</strong> at: <a href='https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/0fo9tt78' target=\"_blank\">https://wandb.ai/cs22m008/Assignment%202%20Part%20A%20main%202.9/runs/0fo9tt78</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230410_195138-0fo9tt78/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]}]}